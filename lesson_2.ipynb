{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "lesson_2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKJ671YjAzhR"
      },
      "source": [
        "# Домашняя работа к уроку 2. Профилирование пользователей. Сегментация аудитории: unsupervised learning (clustering, LDA/ARTM), supervised (multi/binary classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdmo-aYxAzhS"
      },
      "source": [
        "1. Самостоятельно разобраться с тем, что такое tfidf (документация https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html и еще - https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)\n",
        "\n",
        "2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)\n",
        "\n",
        "3. Повторить п.2, но используя уже не медиану, а max\n",
        "\n",
        "4. (опциональное, если очень хочется) Воспользовавшись полученными знаниями из п.1, повторить пункт 2, но уже взвешивая новости по tfidf (подсказка: нужно получить веса-коэффициенты для каждого документа. Не все документы одинаково информативны и несут какой-то положительный сигнал). Подсказка 2 - нужен именно idf, как вес.\n",
        "\n",
        "5. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score\n",
        "\n",
        "6. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных\n",
        "\n",
        "\n",
        "**Ссылки**\n",
        "- http://www.machinelearning.ru/wiki/images/d/d5/Voron17survey-artm.pdf\n",
        "\n",
        "- https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItJ5hmI9AzhT"
      },
      "source": [
        "#### Выполнение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buYCYZQwAzhT"
      },
      "source": [
        "##### 2. Модифицировать код функции get_user_embedding таким образом, чтобы считалось не среднее (как в примере np.mean), а медиана. \n",
        "Применить такое преобразование к данным, обучить модель прогнозирования оттока и посчитать метрики качества и сохранить их: roc auc, precision/recall/f_score (для 3 последних - подобрать оптимальный порог с помощью precision_recall_curve, как это делалось на уроке)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eikvFCqTAzhT"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v-gTb1fAzhT"
      },
      "source": [
        "# Загрузим новости, пользователей пользователей и списки последних прочитанных новостейnews = pd.read_csv(\"/content/drive/MyDrive/articles.csv\")\n",
        "news = pd.read_csv(\"/content/drive/MyDrive/articles.csv\")\n",
        "users = pd.read_csv(\"/content/drive/MyDrive/users_articles.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5ZSIW0HBLlp",
        "outputId": "0e1bb60d-6efc-469e-f893-a315ed281817"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZnKbiq-AzhU",
        "outputId": "64cad53d-db02-43ec-9670-bd6023ac3e30"
      },
      "source": [
        "print(news.shape)\n",
        "print(users.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27000, 2)\n",
            "(8000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "-lDD1ThaAzhU",
        "outputId": "3685ef0e-76e5-4734-aef9-2a133c2a2643"
      },
      "source": [
        "display(news.head(3), users.head(3))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>Заместитель председателяnправительства РФnСерг...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4896</td>\n",
              "      <td>Матч 1/16 финала Кубка России по футболу был п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4897</td>\n",
              "      <td>Форвард «Авангарда» Томаш Заборский прокоммент...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   doc_id                                              title\n",
              "0       6  Заместитель председателяnправительства РФnСерг...\n",
              "1    4896  Матч 1/16 финала Кубка России по футболу был п...\n",
              "2    4897  Форвард «Авангарда» Томаш Заборский прокоммент..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>articles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>u105138</td>\n",
              "      <td>[293672, 293328, 293001, 293622, 293126, 1852]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u108690</td>\n",
              "      <td>[3405, 1739, 2972, 1158, 1599, 322665]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>u108339</td>\n",
              "      <td>[1845, 2009, 2356, 1424, 2939, 323389]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid                                        articles\n",
              "0  u105138  [293672, 293328, 293001, 293622, 293126, 1852]\n",
              "1  u108690          [3405, 1739, 2972, 1158, 1599, 322665]\n",
              "2  u108339          [1845, 2009, 2356, 1424, 2939, 323389]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLH7s9NdAzhU",
        "outputId": "a8ae7944-74ec-4743-a3ba-6035f930e8ed"
      },
      "source": [
        "# Получаем векторные представления новостей\n",
        "\"Gensim — библиотека обработки естественного языка предназначения для «Тематического моделирования».\"\n",
        "!pip install --upgrade gensim"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (4.1.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqb1JNxRAzhU",
        "outputId": "f7d601e7-1a24-4c02-a4e6-16f2c97a3c84"
      },
      "source": [
        "\"Морфологический анализатор pymorphy2\"\n",
        "!pip install pymorphy2"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtoWXcamAzhV",
        "outputId": "4f4ab9d9-44ef-4a93-8270-748ebff3e528"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Np_KtEeAzhV",
        "outputId": "4bd37d1b-642a-40c5-e322-657e81256db6"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUtVHKG_AzhV",
        "outputId": "6b3d2c61-0e81-4918-8054-c33121cdf545"
      },
      "source": [
        "!pip install natasha"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: natasha in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
            "Requirement already satisfied: ipymarkup>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.0)\n",
            "Requirement already satisfied: razdel>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: slovnet>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.5.0)\n",
            "Requirement already satisfied: yargy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.15.0)\n",
            "Requirement already satisfied: navec>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.10.0)\n",
            "Requirement already satisfied: intervaltree>=3 in /usr/local/lib/python3.7/dist-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_CFVLMDAzhV"
      },
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.corpora.dictionary import Dictionary"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-qijYpyAzhV",
        "outputId": "175dee7e-5b6c-4e99-a58b-8e61371aeb52"
      },
      "source": [
        "#предобработка текстов\n",
        "import re\n",
        "import numpy as np\n",
        "from razdel import tokenize\n",
        "import pymorphy2\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XynMT1m6AzhW"
      },
      "source": [
        "stopword_ru = nltk.corpus.stopwords.words('russian')\n",
        "len(stopword_ru)\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y85JolX5AzhW",
        "outputId": "31f316e5-aa6a-40a9-dbb6-2589b8168893"
      },
      "source": [
        "with open('/content/drive/MyDrive/stopwords.txt') as f:\n",
        "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
        "stopword_ru += additional_stopwords\n",
        "len(stopword_ru)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "776"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iebmw8vyAzhW"
      },
      "source": [
        "def clean_text(text):\n",
        "    '''\n",
        "    очистка текста\n",
        "    \n",
        "    на выходе очищеный текст\n",
        "    \n",
        "    '''\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    \n",
        "    text = text.lower()\n",
        "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
        "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
        "\n",
        "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
        "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
        "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
        "    \n",
        "    #tokens = list(tokenize(text))\n",
        "    #words = [_.text for _ in tokens]\n",
        "    #words = [w for w in words if w not in stopword_ru]\n",
        "    \n",
        "    #return \" \".join(words)\n",
        "    return text\n",
        "\n",
        "cache = {}\n",
        "\n",
        "def lemmatization(text):\n",
        "    '''\n",
        "    лемматизация\n",
        "        [0] если зашел тип не `str` делаем его `str`\n",
        "        [1] токенизация предложения через razdel\n",
        "        [2] проверка есть ли в начале слова '-'\n",
        "        [3] проверка токена с одного символа\n",
        "        [4] проверка есть ли данное слово в кэше\n",
        "        [5] лемматизация слова\n",
        "        [6] проверка на стоп-слова\n",
        "\n",
        "    на выходе лист отлемматизированых токенов\n",
        "    '''\n",
        "\n",
        "    # [0]\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    \n",
        "    # [1]\n",
        "    tokens = list(tokenize(text))\n",
        "    words = [_.text for _ in tokens]\n",
        "\n",
        "    words_lem = []\n",
        "    for w in words:\n",
        "        if w[0] == '-': # [2]\n",
        "            w = w[1:]\n",
        "        if len(w)>1: # [3]\n",
        "            if w in cache: # [4]\n",
        "                words_lem.append(cache[w])\n",
        "            else: # [5]\n",
        "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
        "                words_lem.append(temp_cach)\n",
        "    \n",
        "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
        "    \n",
        "    return words_lem_without_stopwords"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIpWouZYAzhX",
        "outputId": "f8879533-96e5-48bb-9aeb-971302fd4bfc"
      },
      "source": [
        "%time\n",
        "#Запускаем очистку текста. Будет долго...\n",
        "news['title'] = news['title'].apply(lambda x: clean_text(x), 1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 7.87 µs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: Possible nested set at position 39\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np2uv2h5AzhX",
        "outputId": "dd51ae08-53bc-4ac7-a888-30e0d26e2220"
      },
      "source": [
        "%time\n",
        "#Запускаем лемматизацию текста. Будет очень долго...\n",
        "news['title'] = news['title'].apply(lambda x: lemmatization(x), 1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 7.63 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jZ-60IHAzhX",
        "outputId": "2cfe0a85-c123-4964-d0ee-ace7a78050eb"
      },
      "source": [
        "# Обучение модели\n",
        "%time\n",
        "# сформируем список наших текстов, разбив еще и на пробелы\n",
        "texts = [t for t in news['title'].values]\n",
        "\n",
        "# Create a corpus from a list of texts\n",
        "common_dictionary = Dictionary(texts)\n",
        "common_corpus = [common_dictionary.doc2bow(text) for text in texts]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 7.63 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAAlJ7ccAzhY",
        "outputId": "e8f8173d-0722-47a3-d7e1-3b504e937c69"
      },
      "source": [
        "#словарь слов\n",
        "print([common_dictionary[i] for i in range(10, 15)])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ватутин', 'взаимодействие', 'власть', 'войти', 'вячеслав']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKQAK9PLAzhY",
        "outputId": "59e33e19-1f31-478b-caa1-951d4769866f"
      },
      "source": [
        "# запуск обучения\n",
        "%time\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "# Train the model on the corpus.\n",
        "lda = LdaModel(common_corpus, num_topics=25, id2word=common_dictionary, passes=5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.48 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS0CuYeUAzhY"
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "# Save model to disk.\n",
        "temp_file = datapath(\"model.lda\")\n",
        "lda.save(temp_file)\n",
        "\n",
        "# Load a potentially pretrained model from disk.\n",
        "lda = LdaModel.load(temp_file)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMwTfKq3AzhY",
        "outputId": "a6319719-b5c8-4481-8d50-b5edb2b7ca7a"
      },
      "source": [
        "# Анализ тем\n",
        "# Create a new corpus, made of previously unseen documents.\n",
        "# Создайте новый корпус, состоящий из ранее невидимых документов.\n",
        "other_texts = [t for t in news['title'].iloc[:3]]\n",
        "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
        "\n",
        "unseen_doc = other_corpus[2]\n",
        "\n",
        "print(other_texts[2])\n",
        "lda[unseen_doc]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['форвард', 'авангард', 'томаш', 'заборский', 'прокомментировать', 'игра', 'команда', 'матч', 'чемпионат', 'кхл', 'против', 'атланта', 'nnnn', 'плохой', 'матч', 'нижний', 'новгород', 'против', 'торпедо', 'настраиваться', 'первый', 'минута', 'включиться', 'заборский', 'получиться', 'забросить', 'быстрый', 'гол', 'задать', 'хороший', 'темп', 'поединок', 'играть', 'хороший', 'сторона', 'пять', 'очко', 'выезд', 'девять', 'хороший']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.40788203),\n",
              " (1, 0.061200526),\n",
              " (7, 0.23695482),\n",
              " (17, 0.10065572),\n",
              " (20, 0.036538508),\n",
              " (22, 0.13718992)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYQqh-PEAzhY",
        "outputId": "d5988960-6c14-402c-98d4-1c997ef6d027"
      },
      "source": [
        "x=lda.show_topics(num_topics=25, num_words=7,formatted=False)\n",
        "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
        "\n",
        "#Below Code Prints Only Words \n",
        "for topic,words in topics_words:\n",
        "    print(\"topic_{}: \".format(topic)+\" \".join(words))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic_0: рак игра сократиться команда медицина лекарство клуб\n",
            "topic_1: миссия медведев контракт естественный лодка соглашение расширить\n",
            "topic_2: станция северный южный иран япония корея метро\n",
            "topic_3: смерть грузия казахстан армения дания умирать медведь\n",
            "topic_4: двигатель испытание запуск офицер катастрофа отряд кость\n",
            "topic_5: британский великобритания египет белый лондон nthe отель\n",
            "topic_6: система новый исследование научный ракета наука первый\n",
            "topic_7: всё очень газета большой ru например проблема\n",
            "topic_8: решение закон статья документ санкция право писать\n",
            "topic_9: сша россия российский военный американский сила армия\n",
            "topic_10: банк рынок ставка клиент объём продажа карта\n",
            "topic_11: обнаружить операция тело опубликовать вода экипаж причина\n",
            "topic_12: снижение доллар восток бизнесмен сектор перевод брюссель\n",
            "topic_13: взрыв виза нанести диапазон подразделение удар земля\n",
            "topic_14: препарат донбасс супруг индия стресс донецкий корейский\n",
            "topic_15: район убийство пострадать произойти местный житель территория\n",
            "topic_16: земля космонавт собственность память клинический гарантия корпус\n",
            "topic_17: тыс область фонд москва регион nn центр\n",
            "topic_18: млрд рубль рост млн цена рынок экономика\n",
            "topic_19: ребёнок газ женщина мужчина всё nn мозг\n",
            "topic_20: россия российский проект путин nn владимир вопрос\n",
            "topic_21: кожа пища надёжный советовать майкл оплатить сибирский\n",
            "topic_22: nn первый день университет исследование место возраст\n",
            "topic_23: топливо долг снизиться мальчик распоряжение освобождение отдых\n",
            "topic_24: украина nn украинский глава погибнуть россия сотрудник\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X15O-UeKAzhZ"
      },
      "source": [
        "# функция, которая будет нам возвращать векторное представление новости\n",
        "def get_lda_vector(text):\n",
        "    unseen_doc = common_dictionary.doc2bow(text)\n",
        "    lda_tuple = lda[unseen_doc]\n",
        "    not_null_topics = dict(\n",
        "        zip([i[0] for i in lda_tuple], [i[1] for i in lda_tuple]))\n",
        "\n",
        "    output_vector = []\n",
        "    for i in range(25):\n",
        "        if i not in not_null_topics:\n",
        "            output_vector.append(0)\n",
        "        else:\n",
        "            output_vector.append(not_null_topics[i])\n",
        "    return np.array(output_vector)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "3H1Qd7ScAzhZ",
        "outputId": "943a88b5-9f6a-4057-c68d-c6b3595f31d5"
      },
      "source": [
        "# вектора новостей\n",
        "topic_matrix = pd.DataFrame([get_lda_vector(text) for text in news['title'].values])\n",
        "topic_matrix.columns = ['topic_{}'.format(i) for i in range(25)]\n",
        "topic_matrix['doc_id'] = news['doc_id'].values\n",
        "topic_matrix = topic_matrix[['doc_id']+['topic_{}'.format(i) for i in range(25)]]\n",
        "topic_matrix.head(5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>topic_2</th>\n",
              "      <th>topic_3</th>\n",
              "      <th>topic_4</th>\n",
              "      <th>topic_5</th>\n",
              "      <th>topic_6</th>\n",
              "      <th>topic_7</th>\n",
              "      <th>topic_8</th>\n",
              "      <th>topic_9</th>\n",
              "      <th>topic_10</th>\n",
              "      <th>topic_11</th>\n",
              "      <th>topic_12</th>\n",
              "      <th>topic_13</th>\n",
              "      <th>topic_14</th>\n",
              "      <th>topic_15</th>\n",
              "      <th>topic_16</th>\n",
              "      <th>topic_17</th>\n",
              "      <th>topic_18</th>\n",
              "      <th>topic_19</th>\n",
              "      <th>topic_20</th>\n",
              "      <th>topic_21</th>\n",
              "      <th>topic_22</th>\n",
              "      <th>topic_23</th>\n",
              "      <th>topic_24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>0.105144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068356</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021936</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047617</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038267</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.711423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4896</td>\n",
              "      <td>0.275288</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.094767</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.369184</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.186023</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053681</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4897</td>\n",
              "      <td>0.407882</td>\n",
              "      <td>0.061201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.236957</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100656</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036536</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137190</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4898</td>\n",
              "      <td>0.188438</td>\n",
              "      <td>0.025920</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041287</td>\n",
              "      <td>0.429115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.1293</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034878</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141934</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4899</td>\n",
              "      <td>0.132109</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.046275</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.141362</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.162233</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494426</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   doc_id   topic_0   topic_1  topic_2  ...  topic_21  topic_22  topic_23  topic_24\n",
              "0       6  0.105144  0.000000      0.0  ...  0.000000  0.038267       0.0  0.711423\n",
              "1    4896  0.275288  0.000000      0.0  ...  0.053681  0.000000       0.0  0.000000\n",
              "2    4897  0.407882  0.061201      0.0  ...  0.000000  0.137190       0.0  0.000000\n",
              "3    4898  0.188438  0.025920      0.0  ...  0.000000  0.000000       0.0  0.000000\n",
              "4    4899  0.132109  0.000000      0.0  ...  0.000000  0.000000       0.0  0.494426\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw9_DIYDAzhZ"
      },
      "source": [
        "# векторные представления пользователей\n",
        "doc_dict = dict(zip(topic_matrix['doc_id'].values, topic_matrix[['topic_{}'.format(i) for i in range(25)]].values))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ii1nhiFfAzhZ",
        "outputId": "0880c6c9-f423-4fde-badb-9ecc3be9714e"
      },
      "source": [
        "user_articles_list = users['articles'].iloc[33]\n",
        "display(user_articles_list, \n",
        "        eval(user_articles_list)\n",
        "       )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[323329, 321961, 324743, 323186, 324632, 474690]'"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[323329, 321961, 324743, 323186, 324632, 474690]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2CfOKzAzhZ"
      },
      "source": [
        "def get_user_embedding_mean(user_articles_list):\n",
        "    user_articles_list = eval(user_articles_list)\n",
        "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
        "    user_vector = np.mean(user_vector, 0)\n",
        "    return user_vector\n",
        "\n",
        "def get_user_embedding_median(user_articles_list):\n",
        "    user_articles_list = eval(user_articles_list)\n",
        "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
        "    user_vector = np.median(user_vector, 0)\n",
        "    return user_vector\n",
        "\n",
        "def get_user_embedding_max(user_articles_list):\n",
        "    user_articles_list = eval(user_articles_list)\n",
        "    user_vector = np.array([doc_dict[doc_id] for doc_id in user_articles_list])\n",
        "    user_vector = np.max(user_vector, 0)\n",
        "    return user_vector"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K9j3zAcAzhZ"
      },
      "source": [
        "def score_with_user_embedding(func):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix\n",
        "\n",
        "    user_embeddings = pd.DataFrame([i for i in users['articles'].apply(lambda x: func(x), 1)])\n",
        "    user_embeddings.columns = [f'topic_{i}' for i in range(25)]\n",
        "    user_embeddings['uid'] = users['uid'].values\n",
        "    user_embeddings = user_embeddings[['uid'] + [f'topic_{i}' for i in range(25)]]\n",
        "\n",
        "    X = pd.merge(user_embeddings, target, 'left')\n",
        "\n",
        "    #разделим данные на train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X[[f'topic_{i}' for i in range(25)]], X['churn'], random_state=0)\n",
        "    \n",
        "    logreg = LogisticRegression()\n",
        "\n",
        "    #обучим наш пайплайн\n",
        "    logreg.fit(X_train, y_train)\n",
        "\n",
        "    #наши прогнозы для тестовой выборки\n",
        "    preds = logreg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Рассчитаем Precision, Recall, F_score, roc_auc_score\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
        "    fscore = (2 * precision * recall) / (precision + recall)\n",
        "    # locate the index of the largest f score\n",
        "    ix = np.argmax(fscore)\n",
        "    roc_auc_score = roc_auc_score(y_test, preds)\n",
        "\n",
        "    return round(thresholds[ix], 4), round(fscore[ix], 4), round(precision[ix], 4), round(recall[ix], 4), round(roc_auc_score, 4)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnBa7i1fAzha"
      },
      "source": [
        "target = pd.read_csv(\"/content/drive/MyDrive/users_churn.csv\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foycDtdHAzha"
      },
      "source": [
        "#### 5. Сформировать на выходе единую таблицу, сравнивающую качество 3 разных метода получения эмбедингов пользователей: mean, median, max, idf_mean по метрикам roc_auc, precision, recall, f_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-vetk-NAzha"
      },
      "source": [
        "results = pd.DataFrame(np.array([\n",
        "    score_with_user_embedding(func=get_user_embedding_mean),\n",
        "    score_with_user_embedding(func=get_user_embedding_median),\n",
        "    score_with_user_embedding(func=get_user_embedding_max)\n",
        "]), columns=['Best Threshold', 'F-Score', 'Precision', 'Recall', 'ROC AUC score'])\n",
        "\n",
        "results['func'] = ['mean', 'median', 'max']\n",
        "results = results.set_index('func')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "dQ79cveFAzha",
        "outputId": "f1f30918-5765-4f58-ae97-5b223e39cbf0"
      },
      "source": [
        "results"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Best Threshold</th>\n",
              "      <th>F-Score</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>ROC AUC score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>func</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.2728</td>\n",
              "      <td>0.7853</td>\n",
              "      <td>0.7463</td>\n",
              "      <td>0.8286</td>\n",
              "      <td>0.9771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median</th>\n",
              "      <td>0.2802</td>\n",
              "      <td>0.8337</td>\n",
              "      <td>0.8008</td>\n",
              "      <td>0.8694</td>\n",
              "      <td>0.9819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.3119</td>\n",
              "      <td>0.8068</td>\n",
              "      <td>0.7527</td>\n",
              "      <td>0.8694</td>\n",
              "      <td>0.9766</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Best Threshold  F-Score  Precision  Recall  ROC AUC score\n",
              "func                                                             \n",
              "mean            0.2728   0.7853     0.7463  0.8286         0.9771\n",
              "median          0.2802   0.8337     0.8008  0.8694         0.9819\n",
              "max             0.3119   0.8068     0.7527  0.8694         0.9766"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV2iwWfpAzha"
      },
      "source": [
        "#### 6. Сделать самостоятельные выводы и предположения о том, почему тот или ной способ оказался эффективнее остальных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357t4qjPAzha"
      },
      "source": [
        "Cамый эффективный способ - через max. Вероятнее всего из-за минимизации разброса интересов пользователя."
      ]
    }
  ]
}